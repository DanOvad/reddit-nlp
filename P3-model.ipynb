{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import regex as re\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>clean_title</th>\n",
       "      <th>selftext_urls</th>\n",
       "      <th>title_urls</th>\n",
       "      <th>clean_selftext</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>num_crossposts</th>\n",
       "      <th>score</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>Subreddit_name</th>\n",
       "      <th>merged</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[D] Hinton responds to Schmidhuber</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hinton responds schmidhuber</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1587609168</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>MachineLearning</td>\n",
       "      <td>0</td>\n",
       "      <td>hinton responds schmidhuber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hinton responds to Schmidhuber</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hinton responds schmidhuber</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1587609111</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>MachineLearning</td>\n",
       "      <td>0</td>\n",
       "      <td>hinton responds schmidhuber</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                title selftext                  clean_title  \\\n",
       "0  [D] Hinton responds to Schmidhuber      NaN  hinton responds schmidhuber   \n",
       "1      Hinton responds to Schmidhuber      NaN  hinton responds schmidhuber   \n",
       "\n",
       "  selftext_urls title_urls clean_selftext  created_utc  num_comments  \\\n",
       "0           NaN        NaN            NaN   1587609168             0   \n",
       "1           NaN        NaN            NaN   1587609111             1   \n",
       "\n",
       "   num_crossposts  score        subreddit  Subreddit_name  \\\n",
       "0               0      1  MachineLearning               0   \n",
       "1               0      1  MachineLearning               0   \n",
       "\n",
       "                        merged  \n",
       "0  hinton responds schmidhuber  \n",
       "1  hinton responds schmidhuber  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the data from the machinelearning and datascience\n",
    "clean = pd.read_csv('./data/clean.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title                 0\n",
       "selftext          16002\n",
       "clean_title          30\n",
       "selftext_urls     31661\n",
       "title_urls        39720\n",
       "clean_selftext    16007\n",
       "created_utc           0\n",
       "num_comments          0\n",
       "num_crossposts        0\n",
       "score                 0\n",
       "subreddit             0\n",
       "Subreddit_name        0\n",
       "merged               20\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If there are NA's in clean_title. Remove them\n",
    "if clean.clean_title.isna().sum() > 0:\n",
    "    clean.drop(labels = clean[clean.clean_title.isna()].index, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to clean out our data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Begin the modeling process\n",
    "\n",
    "- Here lets create our X and y variables\n",
    "- Fit our transformers and create our subsequent models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X variable\n",
    "\n",
    "X = clean['merged']\n",
    "y = clean['Subreddit_name']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a custom stopwords list, lets export sklearn's english stopwords, and add in our own list of stop words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### EDA - sklearn's stopwords, extracted\n",
    "sklearn_stopwords = list(CountVectorizer(stop_words = 'english').get_stop_words())\n",
    "\n",
    "#Custom created list\n",
    "custom_stopwords = ['good','time','python','tool','source','best',\n",
    "                    'learn','science',\n",
    "                    'data','learning','science'] # most common words\n",
    "\n",
    "# Personalized stopwords\n",
    "personal_stopwords = sklearn_stopwords + custom_stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate TFIDF and create transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate TFIDF\n",
    "vec = TfidfVectorizer(stop_words = personal_stopwords, \n",
    "                      max_features = 173,\n",
    "                      max_df = 0.8,\n",
    "                      min_df = 5\n",
    "                     )\n",
    "vec.fit(X_train,y_train)\n",
    "# Extract features names for future use\n",
    "feature_names = vec.get_feature_names()\n",
    "\n",
    "# Transform our data: Train/Test\n",
    "V_train = vec.transform(X_train)\n",
    "V_test = vec.transform(X_test)\n",
    "\n",
    "\n",
    "# convert sparse matrix to dataframe\n",
    "transformed_train_df = pd.DataFrame(V_train.toarray(), \n",
    "                             columns = feature_names)\n",
    "\n",
    "# convert sparse matrix to dataframe\n",
    "transformed_test_df = pd.DataFrame(V_test.toarray(), \n",
    "                             columns = feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29837, 173)\n",
      "(9946, 173)\n"
     ]
    }
   ],
   "source": [
    "print(transformed_train_df.shape)\n",
    "print(transformed_test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.77345845 0.7622319  0.76755489 0.76487347 0.7717446 ]\n",
      "Train Accuracy Score: 0.7713912256594162\n",
      "\n",
      "[0.75577889 0.75213675 0.76772247 0.75615887 0.78079437]\n",
      "Test Accuracy Score: 0.7690528855821436\n",
      "CPU times: user 5.83 s, sys: 374 ms, total: 6.2 s\n",
      "Wall time: 3.94 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Instantiate Logistic Regression\n",
    "lr = LogisticRegression(penalty = 'l2', \n",
    "                        C = 0.8,\n",
    "                        random_state = 42)\n",
    "# Fit\n",
    "lr.fit(transformed_train_df, y_train)\n",
    "\n",
    "# Export coeficients to series\n",
    "lr_coef = pd.Series(np.exp(lr.coef_[0]), index = feature_names)\n",
    "\n",
    "# Print Train Scores\n",
    "print(cross_val_score(lr, transformed_train_df, y_train))\n",
    "print(f\"Train Accuracy Score: {lr.score(transformed_train_df, y_train)}\")\n",
    "print()\n",
    "\n",
    "# Print Train Scores\n",
    "print(cross_val_score(lr, transformed_test_df, y_test))\n",
    "print(f\"Test Accuracy Score: {lr.score(transformed_test_df, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply StandardScaler\n",
    "We will apply StandardScaler to our vectorized train and test data to input into SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate StandardScaler\n",
    "ss = StandardScaler()\n",
    "\n",
    "# fit the transformation to train\n",
    "ss.fit(transformed_train_df, y_train)\n",
    "\n",
    "# transform train/test\n",
    "SS_train = ss.transform(transformed_train_df)\n",
    "SS_test = ss.transform(transformed_test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression with StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.77479893 0.76290214 0.76621418 0.76604659 0.77140942]\n",
      "Train Accuracy Score: 0.7614036263699434\n",
      "\n",
      "[0.75829146 0.75515334 0.76721971 0.74912016 0.77677225]\n",
      "Test Accuracy Score: 0.7598029358536095\n"
     ]
    }
   ],
   "source": [
    "# reapplying a Logistic Regresion\n",
    "tr = LogisticRegression()\n",
    "\n",
    "tr.fit(SS_train, y_train)\n",
    "len(tr.coef_[0])\n",
    "\n",
    "print(cross_val_score(lr, SS_train, y_train))\n",
    "print(f\"Train Accuracy Score: {lr.score(SS_train, y_train)}\")\n",
    "print()\n",
    "\n",
    "# Print Train Scores\n",
    "print(cross_val_score(lr, SS_test, y_test))\n",
    "print(f\"Test Accuracy Score: {lr.score(SS_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC model\n",
    "\n",
    "\n",
    "\n",
    "."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "#svc = SVC()\n",
    "#svc.fit(SS_train, y_train)\n",
    "\n",
    "#print(cross_val_score(svc, SS_train, y_train))\n",
    "#print(f\"Train Accuracy Score: {svc.score(SS_train, y_train)}\")\n",
    "#print()\n",
    "\n",
    "## Print Train Scores\n",
    "#print(cross_val_score(svc, SS_test, y_test))\n",
    "#print(f\"Test Accuracy Score: {svc.score(SS_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#nu_mod = {}\n",
    "#nu_mod['transformer'] = 'cvec'\n",
    "#for key, value in gs.best_params_.items():\n",
    "#    nu_mod[key] = value\n",
    "#    nu_mod['train'] = round(gs.score(X_train,y_train),3)\n",
    "#    nu_mod['test'] = round(gs.score(X_test,y_test),3)\n",
    "#    \n",
    "#    nu_df = pd.DataFrame(nu_mod)\n",
    "#    nu_df\n",
    "#    \n",
    "#nu_df = pd.DataFrame(nu_mod)\n",
    "#nu_df\n",
    "#stored_models = pd.concat([stored_models,nu_df])\n",
    "#stored_models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
